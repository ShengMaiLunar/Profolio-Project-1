---
title: "Housing Analysis Project R"
author: "Sheng Mai"
date: "2025-03-01"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(rmarkdown)
library(ggplot2)
library(dplyr)
library(knitr)
library(glmnet)
library(randomForest)
```

## Introduction

This report analyzes housing prices in King County using a dataset that includes 21,613 observations with various attributes such as price, square footage, number of bedrooms and bathrooms, house condition, and geographic location. Project goal: understanding the key drivers of house prices. The results reveal that square footage and grade have the strongest positive impact on price, while additional bedrooms unexpectedly correlate with lower prices—perhaps indicating that larger homes with more open space are more valuable than those with many small rooms.

Key Findings
  1.House Prices Distribution
The median house price is $450,000, with an average of $540,088.
The most expensive property is valued at $7.7 million, while the least expensive is $75,000.
The price distribution is likely right-skewed due to the high maximum value.

  2.Size and Layout of Homes
The average living area is 2,080 sqft, while the median is 1,910 sqft, indicating that a few large properties skew the mean.
The number of bedrooms typically ranges from 3 to 4, with a maximum of 33, which suggests outliers.
Most homes have 1.75 to 2.5 bathrooms, with a maximum of 8.

  3.Property Conditions and Grades
The condition of homes ranges from 1 (poor) to 5 (excellent), with most homes rated around 3 or 4.
The grade, which measures overall construction and design quality, ranges from 1 to 13, with a median of 7.
    
  4.Geographical Trends
Properties are spread across ZIP codes ranging from 98001 to 98199.
The latitude and longitude data indicate the dataset covers a wide range of locations within King County.

  5.Renovation Trends
Most homes were built between 1951 and 1997 (interquartile range).
The majority of homes have not been renovated, as the median renovation year is 0 (not renovated).

  6.Waterfront and View Influence
Only 0.75% of homes have waterfront access, which may indicate a premium pricing factor.
The view rating ranges from 0 to 4, with most homes having a rating of 0 (no significant view).

We will explore the data, find correlation between variables, and explore how different factors influence house prices.

```{r load-data}
Housing_data <- read.csv("C:\\Users\\15157\\Desktop\\Work\\project1\\kc_house_data.csv")
summary(Housing_data)
plot(Housing_data$price)
```

## Outlier removal

we see from previous plot, that most houses lies below 400,000 price range. Any prices above 400,000 can be considered an outlier. We remove it and see how that influences the data. The removal of outliers significantly reduced the range of house prices, which likely made the model more representative of the majority of homes. However, a warning indicates that some groups with fewer than two data points were dropped, which might affect interpretability.

In the regression summary, Bedrooms have a negative coefficient (-51947.07), meaning that, after controlling for other variables, more bedrooms are associated with lower house prices. This might be due to smaller homes in premium areas having higher prices or other unobserved factors.

Bathrooms have a positive coefficient (9884.13), indicating that increasing the number of bathrooms is associated with higher house prices, though the effect is smaller than that of square footage.

Sqft_living has the largest positive impact (291.27 per square foot), meaning that larger living spaces significantly increase house prices.

```{r outlier}
ggplot(Housing_data, aes(x = factor(grade), y = price)) + geom_violin() + geom_boxplot(width=0.1, outlier.shape=NA)

cleaned_data = Housing_data[Housing_data$price < 4000000, ]
plot(cleaned_data$price)
summary(lm(price ~ bedrooms + bathrooms + sqft_living, data = cleaned_data))
```

## Correlation plots

```{r correlation plots}
corr_model = cor(cleaned_data %>% select(price, sqft_living, bedrooms, bathrooms, grade, condition), use = "complete.obs")
corrplot::corrplot(corr_model, method = "color")
```

## Price per square foot -> further analysis 

```{r new variable}
cleaned_data = cleaned_data %>% mutate(price_per_sqft = price / sqft_living)
log_data = cleaned_data %>% mutate(log_price = log(price))
```

## Multivariable regression 

1. Variables 
In this regression, we are predicting house price using five explanatory variables:

  sqft_living: Total square footage of the living space. Larger homes generally have higher prices.
  
  bedrooms: Number of bedrooms in the house.
  
  bathrooms: Number of bathrooms in the house.
  
  grade: A categorical variable that rates the quality of construction and design, with higher values indicating better quality.
  
  condition: A categorical variable representing the condition of the house (e.g., poor to excellent).

2. Understanding Regression and Model Fit

Regression seeks a best-fit line that predicts the dependent variable (house price) using independent variables (sqft_living, bedrooms, etc.). The difference between the predicted and actual values is called the residual.
  
To evaluate model accuracy, we calculate:

  Sum of Squared Residuals (SSR): Measures the total squared error in predictions.
  
  Mean Squared Error (MSE): Average squared residuals, useful for comparing models.
  
  R^2(coefficient of determination): Explains the proportion of variance in house prices that our model captures. The closer to 1, the better.
  
  p-value: Indicates the statistical significance of each variable.

3. Interpretation of Regression Output

Key Findings:
The multiple R-squared (0.5559) suggests that the model explains about 55.59% of the variance in house prices.
The F-statistic (5407, p < 2.2e-16) confirms that at least one variable significantly contributes to predicting price.

Coefficients:

sqft_living (Estimate = 193.2, p < 2e-16):
Each additional square foot adds $193.20 to the house price.
This is the strongest predictor in the model.

bedrooms (Estimate = -35,510, p < 2e-16):
Unexpectedly negative, meaning more bedrooms decrease price when controlling for other factors.
This might be due to multicollinearity with sqft_living or differences in home design.

bathrooms (Estimate = -18,300, p = 2.3e-08):
Also negative, which is unusual. It could be due to correlation with other features.

grade (Estimate = 110,500, p < 2e-16):
Higher grade significantly increases price.
A one-unit increase in grade raises the price by $110,500.

condition (Estimate = 65,030, p < 2e-16):
A better condition increases price, but it has less impact than grade.

4. Plots

First we have the Residual vs Fitted Plot, where the clustering of plots forms a cone shape that lies within 0 - 1500000 on x and -1e+06 - 2e+06 on y, x = fitted values lm(price ~ sqft_living + bedrooms + bathrooms + grade + conditions) and y = residuals. This suggests that house price variance increases for expensive houses, meaning our model might be missing some key predictors for high-value homes.

For our Q-Q Plot, Most points follow the line, indicating that residuals roughly follow a normal distribution.
However, the trailing off at high quantiles (above 2) suggests that the model struggles with extreme price values (potential outliers).

We then have a scale location plot that looks like a bit hair ball between x = 0 - 1500000 and y = 0 - 3.0 where y = sqrt(standard residual). Residuals are randomly scattered, meaning the model does not show severe patterns of heteroscedasticity. However, the slight fan shape at higher fitted values suggests increasing variance.

Last, we have our Residuals vs Leverage Plot. Most points cluster around low leverage, indicating no extreme influential points.One outlier at leverage = 15,870 suggests a highly influential observation—possibly a luxury home that doesn't fit the pattern.

```{r regression}
reg_model = lm(price ~ sqft_living + bedrooms + bathrooms + grade + condition, data = cleaned_data)
summary(reg_model)
plot(reg_model)
```

## Compare linear regression vs lasso vs ridge 

```{r lasso and ridge }
x = model.matrix(price ~ sqft_living + bedrooms + bathrooms + grade + condition, data = Housing_data)[,-1]
y = Housing_data$price
ridge = cv.glmnet(x, y, alph = 0)
lasso = cv.glmnet(x, y, alpha = 1)
```

## Predictive modeling

```{r random forrest}
rf = randomForest(price ~ sqft_living + bedrooms + bathrooms + grade + condition, data=Housing_data, ntree=500)
varImpPlot(rf)
```

## Model evaluation

```{r}
predicted = predict(rf, Housing_data)
RMSE = sqrt(mean((Housing_data$price - predicted)^2))
print(RMSE)
```

This project analyzes the key factors influencing house prices using multiple statistical and machine learning techniques in R. Through linear regression, we identified that square footage, grade, and condition are the most significant predictors, while additional bedrooms have a counterintuitive negative effect, likely due to space trade-offs. Diagnostic plots revealed heteroscedasticity and potential outliers, suggesting that a simple linear model may not fully capture the complexity of housing prices. To improve model performance, we applied Ridge and Lasso regression, which helped reduce multicollinearity and refine feature selection. Finally, Random Forest provided a more flexible, non-linear approach, highlighting square footage and grade as the most important factors while achieving a reasonable RMSE of 208,667, though some error remained.
